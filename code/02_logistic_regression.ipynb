{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic regression\n",
    "\n",
    "逻辑回归实际上解决的是二分类问题，可以给出分类为0和1的概率，并设置阈值进行分类。阈值通常为0.5，因为sigmoid函数在附近变化幅度大，所以可以认为阈值越接近0.5，分类效果越好。\n",
    "\n",
    "sigmoid函数：\n",
    "\n",
    "$$\n",
    "y(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取MNIST数据集，已下载，从[dataset](./dataset/mnist_784.arff)读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'5'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'4'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'9'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'2'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'3'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'4'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'5'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'6'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "0         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "69995     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "69996     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "69997     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "69998     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "69999     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "       pixel10  ...  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "1          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "2          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "3          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "4          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "...        ...  ...       ...       ...       ...       ...       ...   \n",
       "69995      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "69996      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "69997      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "69998      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "69999      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "       pixel781  pixel782  pixel783  pixel784  class  \n",
       "0           0.0       0.0       0.0       0.0   b'5'  \n",
       "1           0.0       0.0       0.0       0.0   b'0'  \n",
       "2           0.0       0.0       0.0       0.0   b'4'  \n",
       "3           0.0       0.0       0.0       0.0   b'1'  \n",
       "4           0.0       0.0       0.0       0.0   b'9'  \n",
       "...         ...       ...       ...       ...    ...  \n",
       "69995       0.0       0.0       0.0       0.0   b'2'  \n",
       "69996       0.0       0.0       0.0       0.0   b'3'  \n",
       "69997       0.0       0.0       0.0       0.0   b'4'  \n",
       "69998       0.0       0.0       0.0       0.0   b'5'  \n",
       "69999       0.0       0.0       0.0       0.0   b'6'  \n",
       "\n",
       "[70000 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.datasets import fetch_openml\n",
    "# mnist = fetch_openml('mnist_784', version=1)\n",
    "# X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "import scipy.io.arff as arff\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data, meta = arff.loadarff(os.path.join(os.getcwd(),\n",
    "                                   'dataset', 'mnist_784.arff'))\n",
    "mnist = pd.DataFrame(data)\n",
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe82a9a0ac0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "image_show = mnist.iloc[1000, :-1].values.astype(float).reshape(28, 28)\n",
    "plt.imshow(image_show, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据预处理，把数据打散"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000,), (10000, 784), (10000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "mnist_values = mnist.values\n",
    "np.random.shuffle(mnist_values)\n",
    "\n",
    "X_train = mnist_values[:60000, :-1].astype(float)\n",
    "y_train = mnist_values[:60000, -1].astype(int)\n",
    "X_test = mnist_values[60000:, :-1].astype(float)\n",
    "y_test = mnist_values[60000:, -1].astype(int)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用X_train, y_train进行训练，并用X_test进行测试，这是一个多分类问题，用logistic regression的nbinary classifier进行分类，用OvR(One-vs-Rest)的方法，即对每一个类别都训练一个二分类模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 6, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "\n",
    "clf = OneVsRestClassifier(LogisticRegression(penalty='l2', solver='lbfgs',\n",
    "                        max_iter=3000, n_jobs=-1, tol=1e-2))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9157837256400538\n",
      "Recall: 0.9157\n",
      "F1 Score: 0.9156101362807564\n",
      "Confusion Matrix:\n",
      "[[ 921    0    6    3    0    7    7    1   12    2]\n",
      " [   1 1114   11    5    2    1    1    4   16    6]\n",
      " [  10   14  914   21    9    5    7   12   35    3]\n",
      " [   5    0   22  882    1   26    7    7   22   12]\n",
      " [   2    7    5    4  905    1    7    3    9   29]\n",
      " [   9    3    7   40   13  778   23    4   21   14]\n",
      " [   6    3    8    0    4    8  958    0   12    0]\n",
      " [   3    5    9    1   11    2    1  968    3   37]\n",
      " [  10   16   13   20    2   23    6    7  878   16]\n",
      " [   5    2    6   19   25    7    1   33   15  839]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multinomial logistic regression\n",
    "\n",
    "这是针对多分类问题的一种变体\n",
    "\n",
    "we assume that there are K classes, and that the probability of the ith data point belonging to the jth class is given by:\n",
    "\n",
    "$$\\Pr(Y_i=k)=\\frac1Ze^{\\boldsymbol{\\beta}_k\\cdot\\mathbf{X}_i}\\quad,\\quad k\\leq K.$$\n",
    "\n",
    "Z is a normalization constant\n",
    "\n",
    "$$Z=\\sum_{k=1}^{K}e^{{\\boldsymbol{\\beta}_{k}\\cdot\\mathbf{X}_{i}}}$$\n",
    "\n",
    "loss function:\n",
    "\n",
    "$$\\begin{aligned}&L=\\prod_{i=1}^nP(Y_i=y_i)=\\prod_{i=1}^n\\left(\\prod_{j=1}^KP(Y_i=j)^{\\delta_{j,y_i}}\\right)\\end{aligned}$$\n",
    "\n",
    "$$\\left.\\delta_{j,y_i}=\\left\\{\\begin{array}{l}1\\text{ for }j=y_i\\\\0\\text{ otherwise}\\end{array}\\right.\\right.$$\n",
    "\n",
    "to minimize the loss function:\n",
    "\n",
    "$$-\\log L=-\\sum_{i=1}^n\\sum_{j=1}^K\\delta_{j,y_i}\\log(P(Y_i=j)).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the resulting probability of given result is:\n",
    "\n",
    "$$\\Pr(Y_i=k)=\\frac{e^{\\beta_k\\cdot\\mathbf{X}_i}}{\\sum_{j=1}^Ke^{\\beta_j\\cdot\\mathbf{X}_i}}\\quad,\\quad k\\leq K.$$\n",
    "\n",
    "it can be written as:\n",
    "\n",
    "$$\\Pr(Y_i=c)=\\mathrm{softmax}(c,\\boldsymbol{\\beta}_1\\cdot\\mathbf{X}_i,\\ldots,\\boldsymbol{\\beta}_K\\cdot\\mathbf{X}_i)$$\n",
    "\n",
    "$softmax$ denotes the max probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zqy/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/zqy/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "clf_multi = LogisticRegression(random_state=0, solver='lbfgs', \n",
    "                               multi_class='multinomial', max_iter=3000)\n",
    "clf_multi.fit(X_train, y_train)\n",
    "y_pred_multi = clf_multi.predict(X_test)                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算precission, recall, f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9148720856372915\n",
      "Recall: 0.9149\n",
      "F1-score: 0.9148082207679193\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precission_multi = precision_score(y_test, y_pred_multi, average='weighted')\n",
    "recall_multi = recall_score(y_test, y_pred_multi, average='weighted')\n",
    "f1_multi = f1_score(y_test, y_pred_multi, average='weighted')\n",
    "print(f\"Precision: {precission_multi}\")\n",
    "print(f\"Recall: {recall_multi}\")\n",
    "print(f\"F1-score: {f1_multi}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
